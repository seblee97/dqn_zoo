-------------------
CPU ENSEMBLE QR-DQN
-------------------
I0810 22:27:12.930734 135951745819712 xla_bridge.py:897] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 22:27:12.931268 135951745819712 xla_bridge.py:897] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 22:27:12.932195 135951745819712 run_atari.py:92] QR-DQN on Atari on cpu.
I0810 22:27:13.189859 135951745819712 run_atari.py:112] Environment: pong
I0810 22:27:13.190036 135951745819712 run_atari.py:113] Action spec: DiscreteArray(shape=(), dtype=int32, name=action, minimum=0, maximum=5, num_values=6)
I0810 22:27:13.190186 135951745819712 run_atari.py:114] Observation spec: (Array(shape=(210, 160, 3), dtype=dtype('uint8'), name='rgb'), Array(shape=(), dtype=dtype('int32'), name='lives'))
I0810 22:27:14.918371 135951745819712 run_atari.py:289] Training iteration 0.
I0810 22:27:14.918521 135951745819712 run_atari.py:296] Evaluation iteration 0.
I0810 22:27:32.533188 135951745819712 run_atari.py:359] iteration:   0, frame:     0, eval_episode_return: -21.00, train_episode_return:  nan, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  284, train_frame_rate:  nan, train_exploration_epsilon: 1.000, train_state_value: nan, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: nan, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:27:32.769706 135951745819712 run_atari.py:289] Training iteration 1.
I0810 22:27:34.479998 135951745819712 run_atari.py:296] Evaluation iteration 1.
I0810 22:27:51.653904 135951745819712 run_atari.py:359] iteration:   1, frame:  1000, eval_episode_return: -21.00, train_episode_return: -3.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  291, train_frame_rate:  585, train_exploration_epsilon: 1.000, train_state_value: 0.001, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:27:51.887122 135951745819712 run_atari.py:289] Training iteration 2.
I0810 22:27:51.914498 135951745819712 agent.py:270] Begin learning
I0810 22:28:03.717101 135951745819712 run_atari.py:296] Evaluation iteration 2.
I0810 22:28:21.136484 135951745819712 run_atari.py:359] iteration:   2, frame:  2000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   85, train_exploration_epsilon: 0.010, train_state_value: 0.000, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:28:21.370635 135951745819712 run_atari.py:289] Training iteration 3.
I0810 22:28:32.206506 135951745819712 run_atari.py:296] Evaluation iteration 3.
I0810 22:28:49.533850 135951745819712 run_atari.py:359] iteration:   3, frame:  3000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate:   92, train_exploration_epsilon: 0.010, train_state_value: -0.000, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:28:49.769866 135951745819712 run_atari.py:289] Training iteration 4.
I0810 22:29:00.538780 135951745819712 run_atari.py:296] Evaluation iteration 4.
I0810 22:29:17.849853 135951745819712 run_atari.py:359] iteration:   4, frame:  4000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.001, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:29:18.087661 135951745819712 run_atari.py:289] Training iteration 5.
I0810 22:29:28.903994 135951745819712 run_atari.py:296] Evaluation iteration 5.
I0810 22:29:46.327483 135951745819712 run_atari.py:359] iteration:   5, frame:  5000, eval_episode_return: -21.00, train_episode_return:  0.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   92, train_exploration_epsilon: 0.010, train_state_value: -0.001, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:29:46.561273 135951745819712 run_atari.py:289] Training iteration 6.
I0810 22:29:57.380312 135951745819712 run_atari.py:296] Evaluation iteration 6.
I0810 22:30:14.664109 135951745819712 run_atari.py:359] iteration:   6, frame:  6000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate:   92, train_exploration_epsilon: 0.010, train_state_value: -0.001, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:30:14.902966 135951745819712 run_atari.py:289] Training iteration 7.
I0810 22:30:25.683974 135951745819712 run_atari.py:296] Evaluation iteration 7.
I0810 22:30:43.089824 135951745819712 run_atari.py:359] iteration:   7, frame:  7000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:30:43.326732 135951745819712 run_atari.py:289] Training iteration 8.
I0810 22:30:54.018044 135951745819712 run_atari.py:296] Evaluation iteration 8.
I0810 22:31:11.378497 135951745819712 run_atari.py:359] iteration:   8, frame:  8000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   94, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:31:11.616835 135951745819712 run_atari.py:289] Training iteration 9.
I0810 22:31:22.354388 135951745819712 run_atari.py:296] Evaluation iteration 9.
I0810 22:31:39.713526 135951745819712 run_atari.py:359] iteration:   9, frame:  9000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:31:39.951203 135951745819712 run_atari.py:289] Training iteration 10.
I0810 22:31:50.702228 135951745819712 run_atari.py:296] Evaluation iteration 10.
I0810 22:32:08.069594 135951745819712 run_atari.py:359] iteration:  10, frame: 10000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:32:08.307182 135951745819712 run_atari.py:289] Training iteration 11.
I0810 22:32:19.055661 135951745819712 run_atari.py:296] Evaluation iteration 11.
I0810 22:32:36.356117 135951745819712 run_atari.py:359] iteration:  11, frame: 11000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.003, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:32:36.593501 135951745819712 run_atari.py:289] Training iteration 12.
I0810 22:32:47.548729 135951745819712 run_atari.py:296] Evaluation iteration 12.
I0810 22:33:04.896409 135951745819712 run_atari.py:359] iteration:  12, frame: 12000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   91, train_exploration_epsilon: 0.010, train_state_value: -0.003, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:33:05.132075 135951745819712 run_atari.py:289] Training iteration 13.
I0810 22:33:15.953361 135951745819712 run_atari.py:296] Evaluation iteration 13.
I0810 22:33:33.314499 135951745819712 run_atari.py:359] iteration:  13, frame: 13000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   92, train_exploration_epsilon: 0.010, train_state_value: -0.003, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:33:33.552136 135951745819712 run_atari.py:289] Training iteration 14.
I0810 22:33:44.340383 135951745819712 run_atari.py:296] Evaluation iteration 14.
I0810 22:34:01.771713 135951745819712 run_atari.py:359] iteration:  14, frame: 14000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.004, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:34:02.008807 135951745819712 run_atari.py:289] Training iteration 15.
I0810 22:34:12.799142 135951745819712 run_atari.py:296] Evaluation iteration 15.
I0810 22:34:30.079297 135951745819712 run_atari.py:359] iteration:  15, frame: 15000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.005, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:34:30.316177 135951745819712 run_atari.py:289] Training iteration 16.
I0810 22:34:41.150478 135951745819712 run_atari.py:296] Evaluation iteration 16.
I0810 22:34:58.610575 135951745819712 run_atari.py:359] iteration:  16, frame: 16000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  286, train_frame_rate:   92, train_exploration_epsilon: 0.010, train_state_value: -0.005, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:34:58.845294 135951745819712 run_atari.py:289] Training iteration 17.
I0810 22:35:09.646468 135951745819712 run_atari.py:296] Evaluation iteration 17.
I0810 22:35:26.970269 135951745819712 run_atari.py:359] iteration:  17, frame: 17000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.006, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:35:27.205227 135951745819712 run_atari.py:289] Training iteration 18.
I0810 22:35:38.015450 135951745819712 run_atari.py:296] Evaluation iteration 18.
I0810 22:35:55.382100 135951745819712 run_atari.py:359] iteration:  18, frame: 18000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.007, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:35:55.622567 135951745819712 run_atari.py:289] Training iteration 19.
I0810 22:36:06.426335 135951745819712 run_atari.py:296] Evaluation iteration 19.
I0810 22:36:23.819644 135951745819712 run_atari.py:359] iteration:  19, frame: 19000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.007, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:36:24.056113 135951745819712 run_atari.py:289] Training iteration 20.
I0810 22:36:34.848786 135951745819712 run_atari.py:296] Evaluation iteration 20.
I0810 22:36:52.279686 135951745819712 run_atari.py:359] iteration:  20, frame: 20000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.007, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:36:52.518080 135951745819712 run_atari.py:289] Training iteration 21.
I0810 22:37:03.351374 135951745819712 run_atari.py:296] Evaluation iteration 21.
I0810 22:37:20.745408 135951745819712 run_atari.py:359] iteration:  21, frame: 21000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   92, train_exploration_epsilon: 0.010, train_state_value: -0.009, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:37:20.981685 135951745819712 run_atari.py:289] Training iteration 22.
I0810 22:37:31.738198 135951745819712 run_atari.py:296] Evaluation iteration 22.
I0810 22:37:49.134267 135951745819712 run_atari.py:359] iteration:  22, frame: 22000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.010, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:37:49.371669 135951745819712 run_atari.py:289] Training iteration 23.
I0810 22:38:00.178095 135951745819712 run_atari.py:296] Evaluation iteration 23.
I0810 22:38:17.590104 135951745819712 run_atari.py:359] iteration:  23, frame: 23000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.011, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:38:17.824511 135951745819712 run_atari.py:289] Training iteration 24.
I0810 22:38:28.608277 135951745819712 run_atari.py:296] Evaluation iteration 24.
I0810 22:38:46.102589 135951745819712 run_atari.py:359] iteration:  24, frame: 24000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  286, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.012, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:38:46.337195 135951745819712 run_atari.py:289] Training iteration 25.
I0810 22:38:57.121345 135951745819712 run_atari.py:296] Evaluation iteration 25.
I0810 22:39:14.570600 135951745819712 run_atari.py:359] iteration:  25, frame: 25000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.013, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:39:14.807377 135951745819712 run_atari.py:289] Training iteration 26.
I0810 22:39:25.607345 135951745819712 run_atari.py:296] Evaluation iteration 26.
I0810 22:39:43.030424 135951745819712 run_atari.py:359] iteration:  26, frame: 26000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.015, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:39:43.266033 135951745819712 run_atari.py:289] Training iteration 27.
I0810 22:39:54.045044 135951745819712 run_atari.py:296] Evaluation iteration 27.
I0810 22:40:11.476935 135951745819712 run_atari.py:359] iteration:  27, frame: 27000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.017, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:40:11.713558 135951745819712 run_atari.py:289] Training iteration 28.
I0810 22:40:22.486275 135951745819712 run_atari.py:296] Evaluation iteration 28.
I0810 22:40:39.913053 135951745819712 run_atari.py:359] iteration:  28, frame: 28000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.019, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:40:40.148784 135951745819712 run_atari.py:289] Training iteration 29.
I0810 22:40:50.929637 135951745819712 run_atari.py:296] Evaluation iteration 29.
I0810 22:41:08.378920 135951745819712 run_atari.py:359] iteration:  29, frame: 29000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.023, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:41:08.615363 135951745819712 run_atari.py:289] Training iteration 30.
I0810 22:41:19.382168 135951745819712 run_atari.py:296] Evaluation iteration 30.
I0810 22:41:36.804301 135951745819712 run_atari.py:359] iteration:  30, frame: 30000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.028, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:41:37.040664 135951745819712 run_atari.py:289] Training iteration 31.
I0810 22:41:47.867707 135951745819712 run_atari.py:296] Evaluation iteration 31.
I0810 22:42:05.330954 135951745819712 run_atari.py:359] iteration:  31, frame: 31000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  286, train_frame_rate:   92, train_exploration_epsilon: 0.010, train_state_value: -0.035, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:42:05.572388 135951745819712 run_atari.py:289] Training iteration 32.
I0810 22:42:16.480754 135951745819712 run_atari.py:296] Evaluation iteration 32.
I0810 22:42:34.049065 135951745819712 run_atari.py:359] iteration:  32, frame: 32000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  285, train_frame_rate:   92, train_exploration_epsilon: 0.010, train_state_value: -0.043, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:42:34.281563 135951745819712 run_atari.py:289] Training iteration 33.
I0810 22:42:44.904365 135951745819712 run_atari.py:296] Evaluation iteration 33.
I0810 22:43:02.271448 135951745819712 run_atari.py:359] iteration:  33, frame: 33000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   94, train_exploration_epsilon: 0.010, train_state_value: -0.058, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:43:02.506154 135951745819712 run_atari.py:289] Training iteration 34.
I0810 22:43:13.154289 135951745819712 run_atari.py:296] Evaluation iteration 34.
I0810 22:43:30.520118 135951745819712 run_atari.py:359] iteration:  34, frame: 34000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   94, train_exploration_epsilon: 0.010, train_state_value: -0.074, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:43:30.756782 135951745819712 run_atari.py:289] Training iteration 35.
I0810 22:43:41.410911 135951745819712 run_atari.py:296] Evaluation iteration 35.
I0810 22:43:58.809181 135951745819712 run_atari.py:359] iteration:  35, frame: 35000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   94, train_exploration_epsilon: 0.010, train_state_value: -0.087, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:43:59.046008 135951745819712 run_atari.py:289] Training iteration 36.
I0810 22:44:09.678258 135951745819712 run_atari.py:296] Evaluation iteration 36.
I0810 22:44:27.102613 135951745819712 run_atari.py:359] iteration:  36, frame: 36000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate:   94, train_exploration_epsilon: 0.010, train_state_value: -0.130, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:44:27.339825 135951745819712 run_atari.py:289] Training iteration 37.
I0810 22:44:38.048644 135951745819712 run_atari.py:296] Evaluation iteration 37.
I0810 22:44:55.428891 135951745819712 run_atari.py:359] iteration:  37, frame: 37000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   93, train_exploration_epsilon: 0.010, train_state_value: -0.234, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:44:55.666074 135951745819712 run_atari.py:289] Training iteration 38.
I0810 22:45:06.301078 135951745819712 run_atari.py:296] Evaluation iteration 38.
I0810 22:45:23.625365 135951745819712 run_atari.py:359] iteration:  38, frame: 38000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate:   94, train_exploration_epsilon: 0.010, train_state_value: -0.418, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:45:23.857610 135951745819712 run_atari.py:289] Training iteration 39.
I0810 22:45:34.466494 135951745819712 run_atari.py:296] Evaluation iteration 39.
I0810 22:45:51.793484 135951745819712 run_atari.py:359] iteration:  39, frame: 39000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate:   94, train_exploration_epsilon: 0.010, train_state_value: -0.565, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 22:45:52.031522 135951745819712 run_atari.py:289] Training iteration 40.
I0810 22:46:02.633142 135951745819712 run_atari.py:296] Evaluation iteration 40.
I0810 22:46:19.996919 135951745819712 run_atari.py:359] iteration:  40, frame: 40000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate:   94, train_exploration_epsilon: 0.010, train_state_value: -0.741, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
-------------------
CPU QR-DQN
-------------------
I0810 22:46:21.555226 137694252586048 xla_bridge.py:897] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 22:46:21.555708 137694252586048 xla_bridge.py:897] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 22:46:21.556614 137694252586048 run_atari.py:84] QR-DQN on Atari on cpu.
I0810 22:46:21.815790 137694252586048 run_atari.py:108] Environment: pong
I0810 22:46:21.815943 137694252586048 run_atari.py:109] Action spec: DiscreteArray(shape=(), dtype=int32, name=action, minimum=0, maximum=5, num_values=6)
I0810 22:46:21.816116 137694252586048 run_atari.py:110] Observation spec: (Array(shape=(210, 160, 3), dtype=dtype('uint8'), name='rgb'), Array(shape=(), dtype=dtype('int32'), name='lives'))
I0810 22:46:23.362739 137694252586048 run_atari.py:219] Training iteration 0.
I0810 22:46:23.362883 137694252586048 run_atari.py:226] Evaluation iteration 0.
I0810 22:46:38.444770 137694252586048 run_atari.py:253] iteration:   0, frame:     0, eval_episode_return: -21.00, train_episode_return:  nan, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  332, train_frame_rate:  nan, train_exploration_epsilon: 1.000, train_state_value: nan, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:46:38.680582 137694252586048 run_atari.py:219] Training iteration 1.
I0810 22:46:39.322079 137694252586048 run_atari.py:226] Evaluation iteration 1.
I0810 22:46:54.093992 137694252586048 run_atari.py:253] iteration:   1, frame:  1000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  338, train_frame_rate: 1559, train_exploration_epsilon: 1.000, train_state_value: 0.004, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:46:54.328669 137694252586048 run_atari.py:219] Training iteration 2.
I0810 22:46:54.789391 137694252586048 run_atari.py:226] Evaluation iteration 2.
I0810 22:47:09.555755 137694252586048 run_atari.py:253] iteration:   2, frame:  2000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  339, train_frame_rate: 2171, train_exploration_epsilon: 1.000, train_state_value: 0.004, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:47:09.791962 137694252586048 run_atari.py:219] Training iteration 3.
I0810 22:47:09.810820 137694252586048 agent.py:175] Begin learning
I0810 22:47:13.249916 137694252586048 run_atari.py:226] Evaluation iteration 3.
I0810 22:47:28.173099 137694252586048 run_atari.py:253] iteration:   3, frame:  3000, eval_episode_return: -20.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  289, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: 0.020, capped_normalized_return: 0.020, human_gap: 0.980
I0810 22:47:28.408960 137694252586048 run_atari.py:219] Training iteration 4.
I0810 22:47:31.013745 137694252586048 run_atari.py:226] Evaluation iteration 4.
I0810 22:47:45.953658 137694252586048 run_atari.py:253] iteration:   4, frame:  4000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  384, train_exploration_epsilon: 0.010, train_state_value: -0.050, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:47:46.190274 137694252586048 run_atari.py:219] Training iteration 5.
I0810 22:47:48.799946 137694252586048 run_atari.py:226] Evaluation iteration 5.
I0810 22:48:03.752789 137694252586048 run_atari.py:253] iteration:   5, frame:  5000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  383, train_exploration_epsilon: 0.010, train_state_value: -0.378, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:48:03.989050 137694252586048 run_atari.py:219] Training iteration 6.
I0810 22:48:06.561463 137694252586048 run_atari.py:226] Evaluation iteration 6.
I0810 22:48:21.415533 137694252586048 run_atari.py:253] iteration:   6, frame:  6000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  337, train_frame_rate:  389, train_exploration_epsilon: 0.010, train_state_value: -1.230, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:48:21.652795 137694252586048 run_atari.py:219] Training iteration 7.
I0810 22:48:24.246949 137694252586048 run_atari.py:226] Evaluation iteration 7.
I0810 22:48:39.137167 137694252586048 run_atari.py:253] iteration:   7, frame:  7000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  336, train_frame_rate:  386, train_exploration_epsilon: 0.010, train_state_value: -1.994, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:48:39.373906 137694252586048 run_atari.py:219] Training iteration 8.
I0810 22:48:41.936491 137694252586048 run_atari.py:226] Evaluation iteration 8.
I0810 22:48:56.929474 137694252586048 run_atari.py:253] iteration:   8, frame:  8000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  390, train_exploration_epsilon: 0.010, train_state_value: -2.303, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:48:57.166354 137694252586048 run_atari.py:219] Training iteration 9.
I0810 22:48:59.767577 137694252586048 run_atari.py:226] Evaluation iteration 9.
I0810 22:49:14.743161 137694252586048 run_atari.py:253] iteration:   9, frame:  9000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  384, train_exploration_epsilon: 0.010, train_state_value: -2.341, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:49:14.975006 137694252586048 run_atari.py:219] Training iteration 10.
I0810 22:49:17.534860 137694252586048 run_atari.py:226] Evaluation iteration 10.
I0810 22:49:32.436868 137694252586048 run_atari.py:253] iteration:  10, frame: 10000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  336, train_frame_rate:  391, train_exploration_epsilon: 0.010, train_state_value: -2.137, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:49:32.673549 137694252586048 run_atari.py:219] Training iteration 11.
I0810 22:49:35.273379 137694252586048 run_atari.py:226] Evaluation iteration 11.
I0810 22:49:50.246030 137694252586048 run_atari.py:253] iteration:  11, frame: 11000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  385, train_exploration_epsilon: 0.010, train_state_value: -2.200, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:49:50.482738 137694252586048 run_atari.py:219] Training iteration 12.
I0810 22:49:53.048033 137694252586048 run_atari.py:226] Evaluation iteration 12.
I0810 22:50:07.976278 137694252586048 run_atari.py:253] iteration:  12, frame: 12000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  390, train_exploration_epsilon: 0.010, train_state_value: -2.697, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:50:08.209778 137694252586048 run_atari.py:219] Training iteration 13.
I0810 22:50:10.809986 137694252586048 run_atari.py:226] Evaluation iteration 13.
I0810 22:50:25.751817 137694252586048 run_atari.py:253] iteration:  13, frame: 13000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  385, train_exploration_epsilon: 0.010, train_state_value: -2.815, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:50:25.988108 137694252586048 run_atari.py:219] Training iteration 14.
I0810 22:50:28.552462 137694252586048 run_atari.py:226] Evaluation iteration 14.
I0810 22:50:43.450953 137694252586048 run_atari.py:253] iteration:  14, frame: 14000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  336, train_frame_rate:  390, train_exploration_epsilon: 0.010, train_state_value: -2.825, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:50:43.687287 137694252586048 run_atari.py:219] Training iteration 15.
I0810 22:50:46.293600 137694252586048 run_atari.py:226] Evaluation iteration 15.
I0810 22:51:01.284892 137694252586048 run_atari.py:253] iteration:  15, frame: 15000, eval_episode_return: -21.00, train_episode_return: -3.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  384, train_exploration_epsilon: 0.010, train_state_value: -2.890, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:51:01.525307 137694252586048 run_atari.py:219] Training iteration 16.
I0810 22:51:04.115256 137694252586048 run_atari.py:226] Evaluation iteration 16.
I0810 22:51:19.063792 137694252586048 run_atari.py:253] iteration:  16, frame: 16000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  386, train_exploration_epsilon: 0.010, train_state_value: -3.013, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:51:19.299813 137694252586048 run_atari.py:219] Training iteration 17.
I0810 22:51:21.917224 137694252586048 run_atari.py:226] Evaluation iteration 17.
I0810 22:51:36.872941 137694252586048 run_atari.py:253] iteration:  17, frame: 17000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  382, train_exploration_epsilon: 0.010, train_state_value: -2.901, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:51:37.106007 137694252586048 run_atari.py:219] Training iteration 18.
I0810 22:51:39.687370 137694252586048 run_atari.py:226] Evaluation iteration 18.
I0810 22:51:54.646474 137694252586048 run_atari.py:253] iteration:  18, frame: 18000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  387, train_exploration_epsilon: 0.010, train_state_value: -2.899, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:51:54.879270 137694252586048 run_atari.py:219] Training iteration 19.
I0810 22:51:57.505503 137694252586048 run_atari.py:226] Evaluation iteration 19.
I0810 22:52:12.498426 137694252586048 run_atari.py:253] iteration:  19, frame: 19000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  381, train_exploration_epsilon: 0.010, train_state_value: -2.783, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:52:12.735601 137694252586048 run_atari.py:219] Training iteration 20.
I0810 22:52:15.306730 137694252586048 run_atari.py:226] Evaluation iteration 20.
I0810 22:52:30.256752 137694252586048 run_atari.py:253] iteration:  20, frame: 20000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  389, train_exploration_epsilon: 0.010, train_state_value: -2.938, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:52:30.492826 137694252586048 run_atari.py:219] Training iteration 21.
I0810 22:52:33.105844 137694252586048 run_atari.py:226] Evaluation iteration 21.
I0810 22:52:48.047681 137694252586048 run_atari.py:253] iteration:  21, frame: 21000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  383, train_exploration_epsilon: 0.010, train_state_value: -2.883, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:52:48.281804 137694252586048 run_atari.py:219] Training iteration 22.
I0810 22:52:50.853382 137694252586048 run_atari.py:226] Evaluation iteration 22.
I0810 22:53:05.789575 137694252586048 run_atari.py:253] iteration:  22, frame: 22000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  389, train_exploration_epsilon: 0.010, train_state_value: -3.011, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:53:06.023117 137694252586048 run_atari.py:219] Training iteration 23.
I0810 22:53:08.641234 137694252586048 run_atari.py:226] Evaluation iteration 23.
I0810 22:53:23.686398 137694252586048 run_atari.py:253] iteration:  23, frame: 23000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  332, train_frame_rate:  382, train_exploration_epsilon: 0.010, train_state_value: -2.779, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:53:23.920630 137694252586048 run_atari.py:219] Training iteration 24.
I0810 22:53:26.485450 137694252586048 run_atari.py:226] Evaluation iteration 24.
I0810 22:53:41.385151 137694252586048 run_atari.py:253] iteration:  24, frame: 24000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  336, train_frame_rate:  390, train_exploration_epsilon: 0.010, train_state_value: -2.704, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:53:41.622992 137694252586048 run_atari.py:219] Training iteration 25.
I0810 22:53:44.236712 137694252586048 run_atari.py:226] Evaluation iteration 25.
I0810 22:53:59.190778 137694252586048 run_atari.py:253] iteration:  25, frame: 25000, eval_episode_return: -21.00, train_episode_return: -3.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  383, train_exploration_epsilon: 0.010, train_state_value: -2.725, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:53:59.428814 137694252586048 run_atari.py:219] Training iteration 26.
I0810 22:54:02.017451 137694252586048 run_atari.py:226] Evaluation iteration 26.
I0810 22:54:16.932476 137694252586048 run_atari.py:253] iteration:  26, frame: 26000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  386, train_exploration_epsilon: 0.010, train_state_value: -2.882, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:54:17.168789 137694252586048 run_atari.py:219] Training iteration 27.
I0810 22:54:19.801870 137694252586048 run_atari.py:226] Evaluation iteration 27.
I0810 22:54:34.852023 137694252586048 run_atari.py:253] iteration:  27, frame: 27000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  332, train_frame_rate:  380, train_exploration_epsilon: 0.010, train_state_value: -3.103, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:54:35.087840 137694252586048 run_atari.py:219] Training iteration 28.
I0810 22:54:37.647330 137694252586048 run_atari.py:226] Evaluation iteration 28.
I0810 22:54:52.591672 137694252586048 run_atari.py:253] iteration:  28, frame: 28000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  391, train_exploration_epsilon: 0.010, train_state_value: -3.036, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:54:52.828849 137694252586048 run_atari.py:219] Training iteration 29.
I0810 22:54:55.463709 137694252586048 run_atari.py:226] Evaluation iteration 29.
I0810 22:55:10.471609 137694252586048 run_atari.py:253] iteration:  29, frame: 29000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  333, train_frame_rate:  380, train_exploration_epsilon: 0.010, train_state_value: -3.045, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:55:10.709555 137694252586048 run_atari.py:219] Training iteration 30.
I0810 22:55:13.280489 137694252586048 run_atari.py:226] Evaluation iteration 30.
I0810 22:55:28.212615 137694252586048 run_atari.py:253] iteration:  30, frame: 30000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  389, train_exploration_epsilon: 0.010, train_state_value: -2.774, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:55:28.449427 137694252586048 run_atari.py:219] Training iteration 31.
I0810 22:55:31.075636 137694252586048 run_atari.py:226] Evaluation iteration 31.
I0810 22:55:46.086371 137694252586048 run_atari.py:253] iteration:  31, frame: 31000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  333, train_frame_rate:  381, train_exploration_epsilon: 0.010, train_state_value: -2.800, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:55:46.320676 137694252586048 run_atari.py:219] Training iteration 32.
I0810 22:55:48.874686 137694252586048 run_atari.py:226] Evaluation iteration 32.
I0810 22:56:03.793256 137694252586048 run_atari.py:253] iteration:  32, frame: 32000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  335, train_frame_rate:  392, train_exploration_epsilon: 0.010, train_state_value: -2.919, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:56:04.026302 137694252586048 run_atari.py:219] Training iteration 33.
I0810 22:56:06.649056 137694252586048 run_atari.py:226] Evaluation iteration 33.
I0810 22:56:21.649384 137694252586048 run_atari.py:253] iteration:  33, frame: 33000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  333, train_frame_rate:  381, train_exploration_epsilon: 0.010, train_state_value: -2.923, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:56:21.883371 137694252586048 run_atari.py:219] Training iteration 34.
I0810 22:56:24.447185 137694252586048 run_atari.py:226] Evaluation iteration 34.
I0810 22:56:39.412233 137694252586048 run_atari.py:253] iteration:  34, frame: 34000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  390, train_exploration_epsilon: 0.010, train_state_value: -2.661, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:56:39.649183 137694252586048 run_atari.py:219] Training iteration 35.
I0810 22:56:42.284791 137694252586048 run_atari.py:226] Evaluation iteration 35.
I0810 22:56:57.321640 137694252586048 run_atari.py:253] iteration:  35, frame: 35000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  333, train_frame_rate:  379, train_exploration_epsilon: 0.010, train_state_value: -2.679, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:56:57.558095 137694252586048 run_atari.py:219] Training iteration 36.
I0810 22:57:00.132573 137694252586048 run_atari.py:226] Evaluation iteration 36.
I0810 22:57:15.111937 137694252586048 run_atari.py:253] iteration:  36, frame: 36000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  388, train_exploration_epsilon: 0.010, train_state_value: -2.397, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:57:15.343638 137694252586048 run_atari.py:219] Training iteration 37.
I0810 22:57:17.953100 137694252586048 run_atari.py:226] Evaluation iteration 37.
I0810 22:57:32.910759 137694252586048 run_atari.py:253] iteration:  37, frame: 37000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  383, train_exploration_epsilon: 0.010, train_state_value: -2.505, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:57:33.147448 137694252586048 run_atari.py:219] Training iteration 38.
I0810 22:57:35.713039 137694252586048 run_atari.py:226] Evaluation iteration 38.
I0810 22:57:50.685431 137694252586048 run_atari.py:253] iteration:  38, frame: 38000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  390, train_exploration_epsilon: 0.010, train_state_value: -2.880, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:57:50.941639 137694252586048 run_atari.py:219] Training iteration 39.
I0810 22:57:53.574600 137694252586048 run_atari.py:226] Evaluation iteration 39.
I0810 22:58:08.567727 137694252586048 run_atari.py:253] iteration:  39, frame: 39000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  334, train_frame_rate:  380, train_exploration_epsilon: 0.010, train_state_value: -3.005, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:58:08.802289 137694252586048 run_atari.py:219] Training iteration 40.
I0810 22:58:11.360966 137694252586048 run_atari.py:226] Evaluation iteration 40.
I0810 22:58:26.373575 137694252586048 run_atari.py:253] iteration:  40, frame: 40000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  333, train_frame_rate:  391, train_exploration_epsilon: 0.010, train_state_value: -2.801, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
-------------------
CPU DQN
-------------------
I0810 22:58:27.878552 126547151209536 xla_bridge.py:897] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 22:58:27.879058 126547151209536 xla_bridge.py:897] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 22:58:27.880016 126547151209536 run_atari.py:84] DQN on Atari on cpu.
I0810 22:58:28.135537 126547151209536 run_atari.py:116] Environment: pong
I0810 22:58:28.135732 126547151209536 run_atari.py:117] Action spec: DiscreteArray(shape=(), dtype=int32, name=action, minimum=0, maximum=5, num_values=6)
I0810 22:58:28.135907 126547151209536 run_atari.py:118] Observation spec: (Array(shape=(210, 160, 3), dtype=dtype('uint8'), name='rgb'), Array(shape=(), dtype=dtype('int32'), name='lives'))
I0810 22:58:29.582548 126547151209536 run_atari.py:245] Training iteration 0.
I0810 22:58:29.582707 126547151209536 run_atari.py:252] Evaluation iteration 0.
I0810 22:58:44.149075 126547151209536 run_atari.py:280] iteration:   0, frame:     0, eval_episode_return: -21.00, train_episode_return:  nan, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  343, train_frame_rate:  nan, train_exploration_epsilon: 1.000, train_state_value: nan, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:58:44.400247 126547151209536 run_atari.py:245] Training iteration 1.
I0810 22:58:44.647128 126547151209536 agent.py:177] Begin learning
I0810 22:58:48.572752 126547151209536 run_atari.py:252] Evaluation iteration 1.
I0810 22:59:02.876388 126547151209536 run_atari.py:280] iteration:   1, frame:  1000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  240, train_exploration_epsilon: 0.100, train_state_value: 0.033, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:59:03.158623 126547151209536 run_atari.py:245] Training iteration 2.
I0810 22:59:06.938842 126547151209536 run_atari.py:252] Evaluation iteration 2.
I0810 22:59:21.141019 126547151209536 run_atari.py:280] iteration:   2, frame:  2000, eval_episode_return: -20.00, train_episode_return: -3.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  352, train_frame_rate:  265, train_exploration_epsilon: 0.100, train_state_value: -0.008, normalized_return: 0.020, capped_normalized_return: 0.020, human_gap: 0.980
I0810 22:59:21.417835 126547151209536 run_atari.py:245] Training iteration 3.
I0810 22:59:25.154430 126547151209536 run_atari.py:252] Evaluation iteration 3.
I0810 22:59:39.386074 126547151209536 run_atari.py:280] iteration:   3, frame:  3000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.026, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:59:39.678793 126547151209536 run_atari.py:245] Training iteration 4.
I0810 22:59:43.418528 126547151209536 run_atari.py:252] Evaluation iteration 4.
I0810 22:59:57.635599 126547151209536 run_atari.py:280] iteration:   4, frame:  4000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  352, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.058, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 22:59:57.937463 126547151209536 run_atari.py:245] Training iteration 5.
I0810 23:00:01.669684 126547151209536 run_atari.py:252] Evaluation iteration 5.
I0810 23:00:15.894770 126547151209536 run_atari.py:280] iteration:   5, frame:  5000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  352, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.120, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:00:16.197468 126547151209536 run_atari.py:245] Training iteration 6.
I0810 23:00:19.928772 126547151209536 run_atari.py:252] Evaluation iteration 6.
I0810 23:00:34.175620 126547151209536 run_atari.py:280] iteration:   6, frame:  6000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.179, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:00:34.459768 126547151209536 run_atari.py:245] Training iteration 7.
I0810 23:00:38.191414 126547151209536 run_atari.py:252] Evaluation iteration 7.
I0810 23:00:52.474293 126547151209536 run_atari.py:280] iteration:   7, frame:  7000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.239, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:00:52.762651 126547151209536 run_atari.py:245] Training iteration 8.
I0810 23:00:56.502677 126547151209536 run_atari.py:252] Evaluation iteration 8.
I0810 23:01:10.741731 126547151209536 run_atari.py:280] iteration:   8, frame:  8000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.259, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:01:11.028641 126547151209536 run_atari.py:245] Training iteration 9.
I0810 23:01:14.744801 126547151209536 run_atari.py:252] Evaluation iteration 9.
I0810 23:01:29.056316 126547151209536 run_atari.py:280] iteration:   9, frame:  9000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  349, train_frame_rate:  269, train_exploration_epsilon: 0.100, train_state_value: -0.267, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:01:29.340888 126547151209536 run_atari.py:245] Training iteration 10.
I0810 23:01:33.076287 126547151209536 run_atari.py:252] Evaluation iteration 10.
I0810 23:01:47.303225 126547151209536 run_atari.py:280] iteration:  10, frame: 10000, eval_episode_return: -20.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.253, normalized_return: 0.020, capped_normalized_return: 0.020, human_gap: 0.980
I0810 23:01:47.597187 126547151209536 run_atari.py:245] Training iteration 11.
I0810 23:01:51.324381 126547151209536 run_atari.py:252] Evaluation iteration 11.
I0810 23:02:05.613150 126547151209536 run_atari.py:280] iteration:  11, frame: 11000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.300, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:02:05.907034 126547151209536 run_atari.py:245] Training iteration 12.
I0810 23:02:09.654654 126547151209536 run_atari.py:252] Evaluation iteration 12.
I0810 23:02:23.858877 126547151209536 run_atari.py:280] iteration:  12, frame: 12000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  352, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.296, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:02:24.166748 126547151209536 run_atari.py:245] Training iteration 13.
I0810 23:02:27.908990 126547151209536 run_atari.py:252] Evaluation iteration 13.
I0810 23:02:42.137317 126547151209536 run_atari.py:280] iteration:  13, frame: 13000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.309, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:02:42.430113 126547151209536 run_atari.py:245] Training iteration 14.
I0810 23:02:46.160848 126547151209536 run_atari.py:252] Evaluation iteration 14.
I0810 23:03:00.453191 126547151209536 run_atari.py:280] iteration:  14, frame: 14000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.296, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:03:00.739959 126547151209536 run_atari.py:245] Training iteration 15.
I0810 23:03:04.505620 126547151209536 run_atari.py:252] Evaluation iteration 15.
I0810 23:03:18.855007 126547151209536 run_atari.py:280] iteration:  15, frame: 15000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  348, train_frame_rate:  266, train_exploration_epsilon: 0.100, train_state_value: -0.264, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:03:19.152044 126547151209536 run_atari.py:245] Training iteration 16.
I0810 23:03:22.894795 126547151209536 run_atari.py:252] Evaluation iteration 16.
I0810 23:03:37.152590 126547151209536 run_atari.py:280] iteration:  16, frame: 16000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.288, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:03:37.452818 126547151209536 run_atari.py:245] Training iteration 17.
I0810 23:03:41.178232 126547151209536 run_atari.py:252] Evaluation iteration 17.
I0810 23:03:55.420902 126547151209536 run_atari.py:280] iteration:  17, frame: 17000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.314, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:03:55.713964 126547151209536 run_atari.py:245] Training iteration 18.
I0810 23:03:59.445802 126547151209536 run_atari.py:252] Evaluation iteration 18.
I0810 23:04:13.763551 126547151209536 run_atari.py:280] iteration:  18, frame: 18000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  349, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.339, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:04:14.033403 126547151209536 run_atari.py:245] Training iteration 19.
I0810 23:04:17.763110 126547151209536 run_atari.py:252] Evaluation iteration 19.
I0810 23:04:32.052416 126547151209536 run_atari.py:280] iteration:  19, frame: 19000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.303, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:04:32.335448 126547151209536 run_atari.py:245] Training iteration 20.
I0810 23:04:36.063424 126547151209536 run_atari.py:252] Evaluation iteration 20.
I0810 23:04:50.440030 126547151209536 run_atari.py:280] iteration:  20, frame: 20000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  348, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.297, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:04:50.740440 126547151209536 run_atari.py:245] Training iteration 21.
I0810 23:04:54.514940 126547151209536 run_atari.py:252] Evaluation iteration 21.
I0810 23:05:08.829246 126547151209536 run_atari.py:280] iteration:  21, frame: 21000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  349, train_frame_rate:  265, train_exploration_epsilon: 0.100, train_state_value: -0.343, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:05:09.110800 126547151209536 run_atari.py:245] Training iteration 22.
I0810 23:05:12.873301 126547151209536 run_atari.py:252] Evaluation iteration 22.
I0810 23:05:27.177425 126547151209536 run_atari.py:280] iteration:  22, frame: 22000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  266, train_exploration_epsilon: 0.100, train_state_value: -0.312, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:05:27.463850 126547151209536 run_atari.py:245] Training iteration 23.
I0810 23:05:31.198736 126547151209536 run_atari.py:252] Evaluation iteration 23.
I0810 23:05:45.478863 126547151209536 run_atari.py:280] iteration:  23, frame: 23000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.357, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:05:45.778076 126547151209536 run_atari.py:245] Training iteration 24.
I0810 23:05:49.511844 126547151209536 run_atari.py:252] Evaluation iteration 24.
I0810 23:06:03.753341 126547151209536 run_atari.py:280] iteration:  24, frame: 24000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.335, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:06:04.042131 126547151209536 run_atari.py:245] Training iteration 25.
I0810 23:06:07.787574 126547151209536 run_atari.py:252] Evaluation iteration 25.
I0810 23:06:22.044225 126547151209536 run_atari.py:280] iteration:  25, frame: 25000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.349, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:06:22.347723 126547151209536 run_atari.py:245] Training iteration 26.
I0810 23:06:26.084196 126547151209536 run_atari.py:252] Evaluation iteration 26.
I0810 23:06:40.397881 126547151209536 run_atari.py:280] iteration:  26, frame: 26000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  349, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.330, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:06:40.700102 126547151209536 run_atari.py:245] Training iteration 27.
I0810 23:06:44.430545 126547151209536 run_atari.py:252] Evaluation iteration 27.
I0810 23:06:58.689024 126547151209536 run_atari.py:280] iteration:  27, frame: 27000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  268, train_exploration_epsilon: 0.100, train_state_value: -0.389, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:06:58.972712 126547151209536 run_atari.py:245] Training iteration 28.
I0810 23:07:02.720637 126547151209536 run_atari.py:252] Evaluation iteration 28.
I0810 23:07:17.011676 126547151209536 run_atari.py:280] iteration:  28, frame: 28000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.318, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:07:17.284429 126547151209536 run_atari.py:245] Training iteration 29.
I0810 23:07:21.025339 126547151209536 run_atari.py:252] Evaluation iteration 29.
I0810 23:07:35.282116 126547151209536 run_atari.py:280] iteration:  29, frame: 29000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.349, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:07:35.586849 126547151209536 run_atari.py:245] Training iteration 30.
I0810 23:07:39.334438 126547151209536 run_atari.py:252] Evaluation iteration 30.
I0810 23:07:53.650424 126547151209536 run_atari.py:280] iteration:  30, frame: 30000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  349, train_frame_rate:  267, train_exploration_epsilon: 0.100, train_state_value: -0.326, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:07:53.947294 126547151209536 run_atari.py:245] Training iteration 31.
I0810 23:07:57.734428 126547151209536 run_atari.py:252] Evaluation iteration 31.
I0810 23:08:11.987476 126547151209536 run_atari.py:280] iteration:  31, frame: 31000, eval_episode_return: -21.00, train_episode_return: -3.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  264, train_exploration_epsilon: 0.100, train_state_value: -0.346, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:08:12.260936 126547151209536 run_atari.py:245] Training iteration 32.
I0810 23:08:16.077747 126547151209536 run_atari.py:252] Evaluation iteration 32.
I0810 23:08:30.381109 126547151209536 run_atari.py:280] iteration:  32, frame: 32000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  262, train_exploration_epsilon: 0.100, train_state_value: -0.270, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:08:30.684203 126547151209536 run_atari.py:245] Training iteration 33.
I0810 23:08:34.475270 126547151209536 run_atari.py:252] Evaluation iteration 33.
I0810 23:08:48.734350 126547151209536 run_atari.py:280] iteration:  33, frame: 33000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  264, train_exploration_epsilon: 0.100, train_state_value: -0.333, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:08:49.022775 126547151209536 run_atari.py:245] Training iteration 34.
I0810 23:08:52.838152 126547151209536 run_atari.py:252] Evaluation iteration 34.
I0810 23:09:07.152776 126547151209536 run_atari.py:280] iteration:  34, frame: 34000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  349, train_frame_rate:  262, train_exploration_epsilon: 0.100, train_state_value: -0.319, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:09:07.431825 126547151209536 run_atari.py:245] Training iteration 35.
I0810 23:09:11.220845 126547151209536 run_atari.py:252] Evaluation iteration 35.
I0810 23:09:25.470579 126547151209536 run_atari.py:280] iteration:  35, frame: 35000, eval_episode_return: -21.00, train_episode_return: -3.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  351, train_frame_rate:  264, train_exploration_epsilon: 0.100, train_state_value: -0.348, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:09:25.732871 126547151209536 run_atari.py:245] Training iteration 36.
I0810 23:09:29.530087 126547151209536 run_atari.py:252] Evaluation iteration 36.
I0810 23:09:43.888278 126547151209536 run_atari.py:280] iteration:  36, frame: 36000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  348, train_frame_rate:  263, train_exploration_epsilon: 0.100, train_state_value: -0.322, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:09:44.153235 126547151209536 run_atari.py:245] Training iteration 37.
I0810 23:09:47.914402 126547151209536 run_atari.py:252] Evaluation iteration 37.
I0810 23:10:02.200142 126547151209536 run_atari.py:280] iteration:  37, frame: 37000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  266, train_exploration_epsilon: 0.100, train_state_value: -0.336, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:10:02.468829 126547151209536 run_atari.py:245] Training iteration 38.
I0810 23:10:06.252437 126547151209536 run_atari.py:252] Evaluation iteration 38.
I0810 23:10:20.567118 126547151209536 run_atari.py:280] iteration:  38, frame: 38000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  349, train_frame_rate:  264, train_exploration_epsilon: 0.100, train_state_value: -0.284, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:10:20.865183 126547151209536 run_atari.py:245] Training iteration 39.
I0810 23:10:24.642576 126547151209536 run_atari.py:252] Evaluation iteration 39.
I0810 23:10:38.912159 126547151209536 run_atari.py:280] iteration:  39, frame: 39000, eval_episode_return: -20.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  350, train_frame_rate:  265, train_exploration_epsilon: 0.100, train_state_value: -0.327, normalized_return: 0.020, capped_normalized_return: 0.020, human_gap: 0.980
I0810 23:10:39.185554 126547151209536 run_atari.py:245] Training iteration 40.
I0810 23:10:42.981408 126547151209536 run_atari.py:252] Evaluation iteration 40.
I0810 23:10:57.346894 126547151209536 run_atari.py:280] iteration:  40, frame: 40000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  348, train_frame_rate:  263, train_exploration_epsilon: 0.100, train_state_value: -0.349, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
-------------------
GPU ENSEMBLE QR-DQN
-------------------
I0810 23:10:58.903457 130285230359616 xla_bridge.py:897] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 23:10:58.903989 130285230359616 xla_bridge.py:897] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 23:10:58.904934 130285230359616 run_atari.py:92] QR-DQN on Atari on gpu.
2024-08-10 23:10:59.019304: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version (12.6.20). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
I0810 23:10:59.373657 130285230359616 run_atari.py:112] Environment: pong
I0810 23:10:59.373819 130285230359616 run_atari.py:113] Action spec: DiscreteArray(shape=(), dtype=int32, name=action, minimum=0, maximum=5, num_values=6)
I0810 23:10:59.373984 130285230359616 run_atari.py:114] Observation spec: (Array(shape=(210, 160, 3), dtype=dtype('uint8'), name='rgb'), Array(shape=(), dtype=dtype('int32'), name='lives'))
I0810 23:11:02.463780 130285230359616 run_atari.py:289] Training iteration 0.
I0810 23:11:02.463957 130285230359616 run_atari.py:296] Evaluation iteration 0.
I0810 23:11:21.584617 130285230359616 run_atari.py:359] iteration:   0, frame:     0, eval_episode_return: -21.00, train_episode_return:  nan, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  262, train_frame_rate:  nan, train_exploration_epsilon: 1.000, train_state_value: nan, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: nan, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:11:21.812707 130285230359616 run_atari.py:289] Training iteration 1.
I0810 23:11:23.534209 130285230359616 run_atari.py:296] Evaluation iteration 1.
I0810 23:11:41.642870 130285230359616 run_atari.py:359] iteration:   1, frame:  1000, eval_episode_return: -21.00, train_episode_return: -3.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  276, train_frame_rate:  581, train_exploration_epsilon: 1.000, train_state_value: 0.001, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:11:41.877383 130285230359616 run_atari.py:289] Training iteration 2.
I0810 23:11:41.895418 130285230359616 agent.py:270] Begin learning
I0810 23:11:47.350545 130285230359616 run_atari.py:296] Evaluation iteration 2.
I0810 23:12:06.280617 130285230359616 run_atari.py:359] iteration:   2, frame:  2000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  264, train_frame_rate:  183, train_exploration_epsilon: 0.010, train_state_value: 0.000, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:12:06.517302 130285230359616 run_atari.py:289] Training iteration 3.
I0810 23:12:08.343431 130285230359616 run_atari.py:296] Evaluation iteration 3.
I0810 23:12:26.180150 130285230359616 run_atari.py:359] iteration:   3, frame:  3000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  280, train_frame_rate:  548, train_exploration_epsilon: 0.010, train_state_value: -0.000, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:12:26.416194 130285230359616 run_atari.py:289] Training iteration 4.
I0810 23:12:28.239450 130285230359616 run_atari.py:296] Evaluation iteration 4.
I0810 23:12:46.202250 130285230359616 run_atari.py:359] iteration:   4, frame:  4000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  278, train_frame_rate:  549, train_exploration_epsilon: 0.010, train_state_value: -0.001, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:12:46.429572 130285230359616 run_atari.py:289] Training iteration 5.
I0810 23:12:48.272128 130285230359616 run_atari.py:296] Evaluation iteration 5.
I0810 23:13:06.537327 130285230359616 run_atari.py:359] iteration:   5, frame:  5000, eval_episode_return: -21.00, train_episode_return:  0.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  274, train_frame_rate:  543, train_exploration_epsilon: 0.010, train_state_value: -0.001, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:13:06.773455 130285230359616 run_atari.py:289] Training iteration 6.
I0810 23:13:08.586986 130285230359616 run_atari.py:296] Evaluation iteration 6.
I0810 23:13:27.302296 130285230359616 run_atari.py:359] iteration:   6, frame:  6000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  267, train_frame_rate:  551, train_exploration_epsilon: 0.010, train_state_value: -0.001, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:13:27.535578 130285230359616 run_atari.py:289] Training iteration 7.
I0810 23:13:29.356169 130285230359616 run_atari.py:296] Evaluation iteration 7.
I0810 23:13:47.538505 130285230359616 run_atari.py:359] iteration:   7, frame:  7000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  275, train_frame_rate:  549, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:13:47.771638 130285230359616 run_atari.py:289] Training iteration 8.
I0810 23:13:49.623819 130285230359616 run_atari.py:296] Evaluation iteration 8.
I0810 23:14:07.967421 130285230359616 run_atari.py:359] iteration:   8, frame:  8000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  273, train_frame_rate:  540, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:14:08.199892 130285230359616 run_atari.py:289] Training iteration 9.
I0810 23:14:10.056896 130285230359616 run_atari.py:296] Evaluation iteration 9.
I0810 23:14:28.552118 130285230359616 run_atari.py:359] iteration:   9, frame:  9000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  270, train_frame_rate:  539, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:14:28.789319 130285230359616 run_atari.py:289] Training iteration 10.
I0810 23:14:30.633161 130285230359616 run_atari.py:296] Evaluation iteration 10.
I0810 23:14:49.198225 130285230359616 run_atari.py:359] iteration:  10, frame: 10000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  269, train_frame_rate:  542, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:14:49.435206 130285230359616 run_atari.py:289] Training iteration 11.
I0810 23:14:51.276072 130285230359616 run_atari.py:296] Evaluation iteration 11.
I0810 23:15:09.330262 130285230359616 run_atari.py:359] iteration:  11, frame: 11000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  277, train_frame_rate:  543, train_exploration_epsilon: 0.010, train_state_value: -0.003, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:15:09.558985 130285230359616 run_atari.py:289] Training iteration 12.
I0810 23:15:11.391075 130285230359616 run_atari.py:296] Evaluation iteration 12.
I0810 23:15:30.080145 130285230359616 run_atari.py:359] iteration:  12, frame: 12000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  268, train_frame_rate:  546, train_exploration_epsilon: 0.010, train_state_value: -0.003, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:15:30.314689 130285230359616 run_atari.py:289] Training iteration 13.
I0810 23:15:32.162980 130285230359616 run_atari.py:296] Evaluation iteration 13.
I0810 23:15:50.944725 130285230359616 run_atari.py:359] iteration:  13, frame: 13000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  266, train_frame_rate:  541, train_exploration_epsilon: 0.010, train_state_value: -0.003, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:15:51.179709 130285230359616 run_atari.py:289] Training iteration 14.
I0810 23:15:53.040070 130285230359616 run_atari.py:296] Evaluation iteration 14.
I0810 23:16:11.581057 130285230359616 run_atari.py:359] iteration:  14, frame: 14000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  270, train_frame_rate:  538, train_exploration_epsilon: 0.010, train_state_value: -0.004, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:16:11.807725 130285230359616 run_atari.py:289] Training iteration 15.
I0810 23:16:13.654883 130285230359616 run_atari.py:296] Evaluation iteration 15.
I0810 23:16:32.185038 130285230359616 run_atari.py:359] iteration:  15, frame: 15000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  270, train_frame_rate:  541, train_exploration_epsilon: 0.010, train_state_value: -0.005, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:16:32.420548 130285230359616 run_atari.py:289] Training iteration 16.
I0810 23:16:34.270474 130285230359616 run_atari.py:296] Evaluation iteration 16.
I0810 23:16:52.583485 130285230359616 run_atari.py:359] iteration:  16, frame: 16000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  273, train_frame_rate:  541, train_exploration_epsilon: 0.010, train_state_value: -0.005, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:16:52.810864 130285230359616 run_atari.py:289] Training iteration 17.
I0810 23:16:54.658390 130285230359616 run_atari.py:296] Evaluation iteration 17.
I0810 23:17:13.191593 130285230359616 run_atari.py:359] iteration:  17, frame: 17000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  270, train_frame_rate:  541, train_exploration_epsilon: 0.010, train_state_value: -0.006, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:17:13.432583 130285230359616 run_atari.py:289] Training iteration 18.
I0810 23:17:15.283424 130285230359616 run_atari.py:296] Evaluation iteration 18.
I0810 23:17:33.774493 130285230359616 run_atari.py:359] iteration:  18, frame: 18000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  270, train_frame_rate:  540, train_exploration_epsilon: 0.010, train_state_value: -0.007, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:17:34.001548 130285230359616 run_atari.py:289] Training iteration 19.
I0810 23:17:35.857615 130285230359616 run_atari.py:296] Evaluation iteration 19.
I0810 23:17:54.583604 130285230359616 run_atari.py:359] iteration:  19, frame: 19000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  267, train_frame_rate:  539, train_exploration_epsilon: 0.010, train_state_value: -0.007, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:17:54.822789 130285230359616 run_atari.py:289] Training iteration 20.
I0810 23:17:56.692862 130285230359616 run_atari.py:296] Evaluation iteration 20.
I0810 23:18:15.565406 130285230359616 run_atari.py:359] iteration:  20, frame: 20000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  265, train_frame_rate:  535, train_exploration_epsilon: 0.010, train_state_value: -0.007, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:18:15.793435 130285230359616 run_atari.py:289] Training iteration 21.
I0810 23:18:17.653221 130285230359616 run_atari.py:296] Evaluation iteration 21.
I0810 23:18:36.495605 130285230359616 run_atari.py:359] iteration:  21, frame: 21000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  265, train_frame_rate:  538, train_exploration_epsilon: 0.010, train_state_value: -0.009, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:18:36.731303 130285230359616 run_atari.py:289] Training iteration 22.
I0810 23:18:38.583149 130285230359616 run_atari.py:296] Evaluation iteration 22.
I0810 23:18:57.308368 130285230359616 run_atari.py:359] iteration:  22, frame: 22000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  267, train_frame_rate:  540, train_exploration_epsilon: 0.010, train_state_value: -0.010, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:18:57.544213 130285230359616 run_atari.py:289] Training iteration 23.
I0810 23:18:59.407927 130285230359616 run_atari.py:296] Evaluation iteration 23.
I0810 23:19:18.037667 130285230359616 run_atari.py:359] iteration:  23, frame: 23000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  268, train_frame_rate:  537, train_exploration_epsilon: 0.010, train_state_value: -0.011, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:19:18.277894 130285230359616 run_atari.py:289] Training iteration 24.
I0810 23:19:20.116213 130285230359616 run_atari.py:296] Evaluation iteration 24.
I0810 23:19:38.501948 130285230359616 run_atari.py:359] iteration:  24, frame: 24000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  272, train_frame_rate:  544, train_exploration_epsilon: 0.010, train_state_value: -0.013, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:19:38.736839 130285230359616 run_atari.py:289] Training iteration 25.
I0810 23:19:40.624185 130285230359616 run_atari.py:296] Evaluation iteration 25.
I0810 23:19:59.018340 130285230359616 run_atari.py:359] iteration:  25, frame: 25000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  272, train_frame_rate:  530, train_exploration_epsilon: 0.010, train_state_value: -0.014, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:19:59.258547 130285230359616 run_atari.py:289] Training iteration 26.
I0810 23:20:01.096594 130285230359616 run_atari.py:296] Evaluation iteration 26.
I0810 23:20:19.739299 130285230359616 run_atari.py:359] iteration:  26, frame: 26000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  268, train_frame_rate:  544, train_exploration_epsilon: 0.010, train_state_value: -0.016, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:20:19.970019 130285230359616 run_atari.py:289] Training iteration 27.
I0810 23:20:21.836377 130285230359616 run_atari.py:296] Evaluation iteration 27.
I0810 23:20:40.461803 130285230359616 run_atari.py:359] iteration:  27, frame: 27000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  268, train_frame_rate:  536, train_exploration_epsilon: 0.010, train_state_value: -0.019, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:20:40.695182 130285230359616 run_atari.py:289] Training iteration 28.
I0810 23:20:42.578733 130285230359616 run_atari.py:296] Evaluation iteration 28.
I0810 23:21:01.637574 130285230359616 run_atari.py:359] iteration:  28, frame: 28000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  262, train_frame_rate:  531, train_exploration_epsilon: 0.010, train_state_value: -0.021, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:21:01.865633 130285230359616 run_atari.py:289] Training iteration 29.
I0810 23:21:03.727592 130285230359616 run_atari.py:296] Evaluation iteration 29.
I0810 23:21:22.609742 130285230359616 run_atari.py:359] iteration:  29, frame: 29000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  265, train_frame_rate:  537, train_exploration_epsilon: 0.010, train_state_value: -0.027, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:21:22.846518 130285230359616 run_atari.py:289] Training iteration 30.
I0810 23:21:24.712043 130285230359616 run_atari.py:296] Evaluation iteration 30.
I0810 23:21:43.449567 130285230359616 run_atari.py:359] iteration:  30, frame: 30000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  267, train_frame_rate:  536, train_exploration_epsilon: 0.010, train_state_value: -0.032, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:21:43.676827 130285230359616 run_atari.py:289] Training iteration 31.
I0810 23:21:45.525340 130285230359616 run_atari.py:296] Evaluation iteration 31.
I0810 23:22:04.547307 130285230359616 run_atari.py:359] iteration:  31, frame: 31000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  263, train_frame_rate:  541, train_exploration_epsilon: 0.010, train_state_value: -0.042, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:22:04.780259 130285230359616 run_atari.py:289] Training iteration 32.
I0810 23:22:06.625561 130285230359616 run_atari.py:296] Evaluation iteration 32.
I0810 23:22:24.907938 130285230359616 run_atari.py:359] iteration:  32, frame: 32000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  273, train_frame_rate:  542, train_exploration_epsilon: 0.010, train_state_value: -0.056, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:22:25.143359 130285230359616 run_atari.py:289] Training iteration 33.
I0810 23:22:27.011409 130285230359616 run_atari.py:296] Evaluation iteration 33.
I0810 23:22:45.409080 130285230359616 run_atari.py:359] iteration:  33, frame: 33000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  272, train_frame_rate:  535, train_exploration_epsilon: 0.010, train_state_value: -0.076, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:22:45.649491 130285230359616 run_atari.py:289] Training iteration 34.
I0810 23:22:47.529267 130285230359616 run_atari.py:296] Evaluation iteration 34.
I0810 23:23:06.031949 130285230359616 run_atari.py:359] iteration:  34, frame: 34000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  270, train_frame_rate:  532, train_exploration_epsilon: 0.010, train_state_value: -0.104, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:23:06.259902 130285230359616 run_atari.py:289] Training iteration 35.
I0810 23:23:08.111149 130285230359616 run_atari.py:296] Evaluation iteration 35.
I0810 23:23:26.769449 130285230359616 run_atari.py:359] iteration:  35, frame: 35000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  268, train_frame_rate:  540, train_exploration_epsilon: 0.010, train_state_value: -0.139, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:23:27.002243 130285230359616 run_atari.py:289] Training iteration 36.
I0810 23:23:28.834774 130285230359616 run_atari.py:296] Evaluation iteration 36.
I0810 23:23:47.259153 130285230359616 run_atari.py:359] iteration:  36, frame: 36000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  271, train_frame_rate:  546, train_exploration_epsilon: 0.010, train_state_value: -0.227, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:23:47.487503 130285230359616 run_atari.py:289] Training iteration 37.
I0810 23:23:49.326545 130285230359616 run_atari.py:296] Evaluation iteration 37.
I0810 23:24:07.848263 130285230359616 run_atari.py:359] iteration:  37, frame: 37000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  270, train_frame_rate:  544, train_exploration_epsilon: 0.010, train_state_value: -0.414, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:24:08.087473 130285230359616 run_atari.py:289] Training iteration 38.
I0810 23:24:09.937926 130285230359616 run_atari.py:296] Evaluation iteration 38.
I0810 23:24:28.536364 130285230359616 run_atari.py:359] iteration:  38, frame: 38000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  269, train_frame_rate:  540, train_exploration_epsilon: 0.010, train_state_value: -0.581, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:24:28.764365 130285230359616 run_atari.py:289] Training iteration 39.
I0810 23:24:30.617407 130285230359616 run_atari.py:296] Evaluation iteration 39.
I0810 23:24:49.293369 130285230359616 run_atari.py:359] iteration:  39, frame: 39000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  268, train_frame_rate:  540, train_exploration_epsilon: 0.010, train_state_value: -0.831, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
I0810 23:24:49.528481 130285230359616 run_atari.py:289] Training iteration 40.
I0810 23:24:51.376360 130285230359616 run_atari.py:296] Evaluation iteration 40.
I0810 23:25:09.763532 130285230359616 run_atari.py:359] iteration:  40, frame: 40000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  272, train_frame_rate:  541, train_exploration_epsilon: 0.010, train_state_value: -1.051, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008, train_loss: 0.00000, eval_loss: 0.00000, train_episode_length: nan, eval_episode_length: 1000.00, td_errors: nan, mean_q: nan, mean_q_var: nan, mean_epistemic: nan, mean_aleatoric: nan, q_select: nan, q_var_select: nan, epistemic_select: nan, aleatoric_select: nan
-------------------
GPU QR-DQN
-------------------
I0810 23:25:11.512160 133234399966272 xla_bridge.py:897] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 23:25:11.512681 133234399966272 xla_bridge.py:897] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 23:25:11.513612 133234399966272 run_atari.py:84] QR-DQN on Atari on gpu.
2024-08-10 23:25:11.532415: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version (12.6.20). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
I0810 23:25:11.827399 133234399966272 run_atari.py:108] Environment: pong
I0810 23:25:11.827538 133234399966272 run_atari.py:109] Action spec: DiscreteArray(shape=(), dtype=int32, name=action, minimum=0, maximum=5, num_values=6)
I0810 23:25:11.827718 133234399966272 run_atari.py:110] Observation spec: (Array(shape=(210, 160, 3), dtype=dtype('uint8'), name='rgb'), Array(shape=(), dtype=dtype('int32'), name='lives'))
I0810 23:25:14.479527 133234399966272 run_atari.py:219] Training iteration 0.
I0810 23:25:14.479668 133234399966272 run_atari.py:226] Evaluation iteration 0.
I0810 23:25:33.019141 133234399966272 run_atari.py:253] iteration:   0, frame:     0, eval_episode_return: -21.00, train_episode_return:  nan, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  270, train_frame_rate:  nan, train_exploration_epsilon: 1.000, train_state_value: nan, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:25:33.253858 133234399966272 run_atari.py:219] Training iteration 1.
I0810 23:25:34.109171 133234399966272 run_atari.py:226] Evaluation iteration 1.
I0810 23:25:51.901177 133234399966272 run_atari.py:253] iteration:   1, frame:  1000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  281, train_frame_rate: 1169, train_exploration_epsilon: 1.000, train_state_value: 0.004, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:25:52.130186 133234399966272 run_atari.py:219] Training iteration 2.
I0810 23:25:52.504955 133234399966272 run_atari.py:226] Evaluation iteration 2.
I0810 23:26:10.167921 133234399966272 run_atari.py:253] iteration:   2, frame:  2000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  283, train_frame_rate: 2669, train_exploration_epsilon: 1.000, train_state_value: 0.004, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:26:10.402772 133234399966272 run_atari.py:219] Training iteration 3.
I0810 23:26:10.418533 133234399966272 agent.py:175] Begin learning
I0810 23:26:14.407556 133234399966272 run_atari.py:226] Evaluation iteration 3.
I0810 23:26:32.022383 133234399966272 run_atari.py:253] iteration:   3, frame:  3000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  284, train_frame_rate:  250, train_exploration_epsilon: 0.010, train_state_value: -0.002, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:26:32.257518 133234399966272 run_atari.py:219] Training iteration 4.
I0810 23:26:32.840640 133234399966272 run_atari.py:226] Evaluation iteration 4.
I0810 23:26:50.794812 133234399966272 run_atari.py:253] iteration:   4, frame:  4000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  278, train_frame_rate: 1715, train_exploration_epsilon: 0.010, train_state_value: -0.049, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:26:51.032642 133234399966272 run_atari.py:219] Training iteration 5.
I0810 23:26:51.618613 133234399966272 run_atari.py:226] Evaluation iteration 5.
I0810 23:27:09.438693 133234399966272 run_atari.py:253] iteration:   5, frame:  5000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  281, train_frame_rate: 1707, train_exploration_epsilon: 0.010, train_state_value: -0.374, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:27:09.672314 133234399966272 run_atari.py:219] Training iteration 6.
I0810 23:27:10.261266 133234399966272 run_atari.py:226] Evaluation iteration 6.
I0810 23:27:28.298004 133234399966272 run_atari.py:253] iteration:   6, frame:  6000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  277, train_frame_rate: 1698, train_exploration_epsilon: 0.010, train_state_value: -1.193, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:27:28.532318 133234399966272 run_atari.py:219] Training iteration 7.
I0810 23:27:29.111488 133234399966272 run_atari.py:226] Evaluation iteration 7.
I0810 23:27:47.140505 133234399966272 run_atari.py:253] iteration:   7, frame:  7000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  277, train_frame_rate: 1727, train_exploration_epsilon: 0.010, train_state_value: -1.889, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:27:47.376364 133234399966272 run_atari.py:219] Training iteration 8.
I0810 23:27:47.956735 133234399966272 run_atari.py:226] Evaluation iteration 8.
I0810 23:28:05.679195 133234399966272 run_atari.py:253] iteration:   8, frame:  8000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  282, train_frame_rate: 1723, train_exploration_epsilon: 0.010, train_state_value: -2.177, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:28:05.906176 133234399966272 run_atari.py:219] Training iteration 9.
I0810 23:28:06.494432 133234399966272 run_atari.py:226] Evaluation iteration 9.
I0810 23:28:24.015573 133234399966272 run_atari.py:253] iteration:   9, frame:  9000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  285, train_frame_rate: 1700, train_exploration_epsilon: 0.010, train_state_value: -2.223, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:28:24.253663 133234399966272 run_atari.py:219] Training iteration 10.
I0810 23:28:24.847841 133234399966272 run_atari.py:226] Evaluation iteration 10.
I0810 23:28:42.474723 133234399966272 run_atari.py:253] iteration:  10, frame: 10000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  284, train_frame_rate: 1683, train_exploration_epsilon: 0.010, train_state_value: -2.243, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:28:42.709380 133234399966272 run_atari.py:219] Training iteration 11.
I0810 23:28:43.303153 133234399966272 run_atari.py:226] Evaluation iteration 11.
I0810 23:29:00.830094 133234399966272 run_atari.py:253] iteration:  11, frame: 11000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  285, train_frame_rate: 1684, train_exploration_epsilon: 0.010, train_state_value: -2.317, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:29:01.065910 133234399966272 run_atari.py:219] Training iteration 12.
I0810 23:29:01.655261 133234399966272 run_atari.py:226] Evaluation iteration 12.
I0810 23:29:19.219633 133234399966272 run_atari.py:253] iteration:  12, frame: 12000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  285, train_frame_rate: 1697, train_exploration_epsilon: 0.010, train_state_value: -2.775, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:29:19.454274 133234399966272 run_atari.py:219] Training iteration 13.
I0810 23:29:20.039962 133234399966272 run_atari.py:226] Evaluation iteration 13.
I0810 23:29:37.956089 133234399966272 run_atari.py:253] iteration:  13, frame: 13000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  279, train_frame_rate: 1708, train_exploration_epsilon: 0.010, train_state_value: -2.792, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:29:38.185331 133234399966272 run_atari.py:219] Training iteration 14.
I0810 23:29:38.780610 133234399966272 run_atari.py:226] Evaluation iteration 14.
I0810 23:29:56.584052 133234399966272 run_atari.py:253] iteration:  14, frame: 14000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  281, train_frame_rate: 1680, train_exploration_epsilon: 0.010, train_state_value: -2.668, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:29:56.819932 133234399966272 run_atari.py:219] Training iteration 15.
I0810 23:29:57.425523 133234399966272 run_atari.py:226] Evaluation iteration 15.
I0810 23:30:15.078168 133234399966272 run_atari.py:253] iteration:  15, frame: 15000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  283, train_frame_rate: 1652, train_exploration_epsilon: 0.010, train_state_value: -2.632, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:30:15.312771 133234399966272 run_atari.py:219] Training iteration 16.
I0810 23:30:15.908236 133234399966272 run_atari.py:226] Evaluation iteration 16.
I0810 23:30:34.008105 133234399966272 run_atari.py:253] iteration:  16, frame: 16000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  276, train_frame_rate: 1680, train_exploration_epsilon: 0.010, train_state_value: -2.669, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:30:34.236362 133234399966272 run_atari.py:219] Training iteration 17.
I0810 23:30:34.822161 133234399966272 run_atari.py:226] Evaluation iteration 17.
I0810 23:30:52.441150 133234399966272 run_atari.py:253] iteration:  17, frame: 17000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  284, train_frame_rate: 1708, train_exploration_epsilon: 0.010, train_state_value: -2.593, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:30:52.670485 133234399966272 run_atari.py:219] Training iteration 18.
I0810 23:30:53.263091 133234399966272 run_atari.py:226] Evaluation iteration 18.
I0810 23:31:11.126116 133234399966272 run_atari.py:253] iteration:  18, frame: 18000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  280, train_frame_rate: 1688, train_exploration_epsilon: 0.010, train_state_value: -2.525, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:31:11.354567 133234399966272 run_atari.py:219] Training iteration 19.
I0810 23:31:11.941310 133234399966272 run_atari.py:226] Evaluation iteration 19.
I0810 23:31:29.756160 133234399966272 run_atari.py:253] iteration:  19, frame: 19000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  281, train_frame_rate: 1705, train_exploration_epsilon: 0.010, train_state_value: -2.512, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:31:29.995537 133234399966272 run_atari.py:219] Training iteration 20.
I0810 23:31:30.591761 133234399966272 run_atari.py:226] Evaluation iteration 20.
I0810 23:31:48.021847 133234399966272 run_atari.py:253] iteration:  20, frame: 20000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate: 1678, train_exploration_epsilon: 0.010, train_state_value: -2.721, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:31:48.256271 133234399966272 run_atari.py:219] Training iteration 21.
I0810 23:31:48.840730 133234399966272 run_atari.py:226] Evaluation iteration 21.
I0810 23:32:07.120415 133234399966272 run_atari.py:253] iteration:  21, frame: 21000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  274, train_frame_rate: 1711, train_exploration_epsilon: 0.010, train_state_value: -2.639, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:32:07.351287 133234399966272 run_atari.py:219] Training iteration 22.
I0810 23:32:07.946842 133234399966272 run_atari.py:226] Evaluation iteration 22.
I0810 23:32:25.754209 133234399966272 run_atari.py:253] iteration:  22, frame: 22000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  281, train_frame_rate: 1679, train_exploration_epsilon: 0.010, train_state_value: -2.621, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:32:25.985189 133234399966272 run_atari.py:219] Training iteration 23.
I0810 23:32:26.570496 133234399966272 run_atari.py:226] Evaluation iteration 23.
I0810 23:32:44.319501 133234399966272 run_atari.py:253] iteration:  23, frame: 23000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  282, train_frame_rate: 1709, train_exploration_epsilon: 0.010, train_state_value: -2.669, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:32:44.555290 133234399966272 run_atari.py:219] Training iteration 24.
I0810 23:32:45.150079 133234399966272 run_atari.py:226] Evaluation iteration 24.
I0810 23:33:02.923115 133234399966272 run_atari.py:253] iteration:  24, frame: 24000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  281, train_frame_rate: 1682, train_exploration_epsilon: 0.010, train_state_value: -2.676, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:33:03.150666 133234399966272 run_atari.py:219] Training iteration 25.
I0810 23:33:03.743897 133234399966272 run_atari.py:226] Evaluation iteration 25.
I0810 23:33:22.032224 133234399966272 run_atari.py:253] iteration:  25, frame: 25000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  273, train_frame_rate: 1686, train_exploration_epsilon: 0.010, train_state_value: -2.929, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:33:22.266821 133234399966272 run_atari.py:219] Training iteration 26.
I0810 23:33:22.862115 133234399966272 run_atari.py:226] Evaluation iteration 26.
I0810 23:33:40.717620 133234399966272 run_atari.py:253] iteration:  26, frame: 26000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  280, train_frame_rate: 1680, train_exploration_epsilon: 0.010, train_state_value: -3.133, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:33:40.945239 133234399966272 run_atari.py:219] Training iteration 27.
I0810 23:33:41.539534 133234399966272 run_atari.py:226] Evaluation iteration 27.
I0810 23:33:59.552532 133234399966272 run_atari.py:253] iteration:  27, frame: 27000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  278, train_frame_rate: 1683, train_exploration_epsilon: 0.010, train_state_value: -3.024, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:33:59.781464 133234399966272 run_atari.py:219] Training iteration 28.
I0810 23:34:00.370533 133234399966272 run_atari.py:226] Evaluation iteration 28.
I0810 23:34:18.142460 133234399966272 run_atari.py:253] iteration:  28, frame: 28000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  281, train_frame_rate: 1698, train_exploration_epsilon: 0.010, train_state_value: -3.215, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:34:18.375125 133234399966272 run_atari.py:219] Training iteration 29.
I0810 23:34:18.969516 133234399966272 run_atari.py:226] Evaluation iteration 29.
I0810 23:34:36.609148 133234399966272 run_atari.py:253] iteration:  29, frame: 29000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  283, train_frame_rate: 1683, train_exploration_epsilon: 0.010, train_state_value: -2.918, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:34:36.843463 133234399966272 run_atari.py:219] Training iteration 30.
I0810 23:34:37.441538 133234399966272 run_atari.py:226] Evaluation iteration 30.
I0810 23:34:55.369067 133234399966272 run_atari.py:253] iteration:  30, frame: 30000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  279, train_frame_rate: 1672, train_exploration_epsilon: 0.010, train_state_value: -2.647, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:34:55.598221 133234399966272 run_atari.py:219] Training iteration 31.
I0810 23:34:56.186720 133234399966272 run_atari.py:226] Evaluation iteration 31.
I0810 23:35:13.874368 133234399966272 run_atari.py:253] iteration:  31, frame: 31000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  283, train_frame_rate: 1700, train_exploration_epsilon: 0.010, train_state_value: -2.861, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:35:14.103017 133234399966272 run_atari.py:219] Training iteration 32.
I0810 23:35:14.684804 133234399966272 run_atari.py:226] Evaluation iteration 32.
I0810 23:35:32.050623 133234399966272 run_atari.py:253] iteration:  32, frame: 32000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate: 1719, train_exploration_epsilon: 0.010, train_state_value: -2.944, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:35:32.286945 133234399966272 run_atari.py:219] Training iteration 33.
I0810 23:35:32.869872 133234399966272 run_atari.py:226] Evaluation iteration 33.
I0810 23:35:50.063350 133234399966272 run_atari.py:253] iteration:  33, frame: 33000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  291, train_frame_rate: 1716, train_exploration_epsilon: 0.010, train_state_value: -3.214, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:35:50.298977 133234399966272 run_atari.py:219] Training iteration 34.
I0810 23:35:50.883247 133234399966272 run_atari.py:226] Evaluation iteration 34.
I0810 23:36:08.107374 133234399966272 run_atari.py:253] iteration:  34, frame: 34000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  290, train_frame_rate: 1712, train_exploration_epsilon: 0.010, train_state_value: -2.816, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:36:08.342008 133234399966272 run_atari.py:219] Training iteration 35.
I0810 23:36:08.928685 133234399966272 run_atari.py:226] Evaluation iteration 35.
I0810 23:36:26.345873 133234399966272 run_atari.py:253] iteration:  35, frame: 35000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  287, train_frame_rate: 1705, train_exploration_epsilon: 0.010, train_state_value: -2.661, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:36:26.581098 133234399966272 run_atari.py:219] Training iteration 36.
I0810 23:36:27.160901 133234399966272 run_atari.py:226] Evaluation iteration 36.
I0810 23:36:45.192876 133234399966272 run_atari.py:253] iteration:  36, frame: 36000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  277, train_frame_rate: 1725, train_exploration_epsilon: 0.010, train_state_value: -2.601, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:36:45.428716 133234399966272 run_atari.py:219] Training iteration 37.
I0810 23:36:46.026329 133234399966272 run_atari.py:226] Evaluation iteration 37.
I0810 23:37:03.130705 133234399966272 run_atari.py:253] iteration:  37, frame: 37000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  292, train_frame_rate: 1674, train_exploration_epsilon: 0.010, train_state_value: -2.592, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:37:03.366572 133234399966272 run_atari.py:219] Training iteration 38.
I0810 23:37:03.949538 133234399966272 run_atari.py:226] Evaluation iteration 38.
I0810 23:37:21.147586 133234399966272 run_atari.py:253] iteration:  38, frame: 38000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  291, train_frame_rate: 1716, train_exploration_epsilon: 0.010, train_state_value: -2.767, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:37:21.384371 133234399966272 run_atari.py:219] Training iteration 39.
I0810 23:37:21.969260 133234399966272 run_atari.py:226] Evaluation iteration 39.
I0810 23:37:39.517598 133234399966272 run_atari.py:253] iteration:  39, frame: 39000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  285, train_frame_rate: 1710, train_exploration_epsilon: 0.010, train_state_value: -2.671, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:37:39.755238 133234399966272 run_atari.py:219] Training iteration 40.
I0810 23:37:40.350823 133234399966272 run_atari.py:226] Evaluation iteration 40.
I0810 23:37:58.216085 133234399966272 run_atari.py:253] iteration:  40, frame: 40000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  280, train_frame_rate: 1679, train_exploration_epsilon: 0.010, train_state_value: -2.565, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
-------------------
GPU DQN
-------------------
I0810 23:37:59.788617 130286664614976 xla_bridge.py:897] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 23:37:59.789177 130286664614976 xla_bridge.py:897] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 23:37:59.790180 130286664614976 run_atari.py:84] DQN on Atari on gpu.
2024-08-10 23:37:59.808875: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version (12.6.20). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
I0810 23:38:00.070590 130286664614976 run_atari.py:116] Environment: pong
I0810 23:38:00.070738 130286664614976 run_atari.py:117] Action spec: DiscreteArray(shape=(), dtype=int32, name=action, minimum=0, maximum=5, num_values=6)
I0810 23:38:00.070877 130286664614976 run_atari.py:118] Observation spec: (Array(shape=(210, 160, 3), dtype=dtype('uint8'), name='rgb'), Array(shape=(), dtype=dtype('int32'), name='lives'))
I0810 23:38:02.594462 130286664614976 run_atari.py:245] Training iteration 0.
I0810 23:38:02.594597 130286664614976 run_atari.py:252] Evaluation iteration 0.
I0810 23:38:20.389422 130286664614976 run_atari.py:280] iteration:   0, frame:     0, eval_episode_return: -21.00, train_episode_return:  nan, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  281, train_frame_rate:  nan, train_exploration_epsilon: 1.000, train_state_value: nan, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:38:20.645754 130286664614976 run_atari.py:245] Training iteration 1.
I0810 23:38:21.193117 130286664614976 agent.py:177] Begin learning
I0810 23:38:24.103875 130286664614976 run_atari.py:252] Evaluation iteration 1.
I0810 23:38:41.367898 130286664614976 run_atari.py:280] iteration:   1, frame:  1000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  290, train_frame_rate:  289, train_exploration_epsilon: 0.100, train_state_value: 0.031, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:38:41.688393 130286664614976 run_atari.py:245] Training iteration 2.
I0810 23:38:42.532537 130286664614976 run_atari.py:252] Evaluation iteration 2.
I0810 23:38:59.525324 130286664614976 run_atari.py:280] iteration:   2, frame:  2000, eval_episode_return: -20.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  294, train_frame_rate: 1185, train_exploration_epsilon: 0.100, train_state_value: -0.053, normalized_return: 0.020, capped_normalized_return: 0.020, human_gap: 0.980
I0810 23:38:59.838890 130286664614976 run_atari.py:245] Training iteration 3.
I0810 23:39:00.669527 130286664614976 run_atari.py:252] Evaluation iteration 3.
I0810 23:39:17.625417 130286664614976 run_atari.py:280] iteration:   3, frame:  3000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  295, train_frame_rate: 1204, train_exploration_epsilon: 0.100, train_state_value: -0.152, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:39:17.938677 130286664614976 run_atari.py:245] Training iteration 4.
I0810 23:39:18.757615 130286664614976 run_atari.py:252] Evaluation iteration 4.
I0810 23:39:35.635326 130286664614976 run_atari.py:280] iteration:   4, frame:  4000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  296, train_frame_rate: 1221, train_exploration_epsilon: 0.100, train_state_value: -0.246, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:39:35.946058 130286664614976 run_atari.py:245] Training iteration 5.
I0810 23:39:36.770599 130286664614976 run_atari.py:252] Evaluation iteration 5.
I0810 23:39:54.047783 130286664614976 run_atari.py:280] iteration:   5, frame:  5000, eval_episode_return: -20.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate: 1213, train_exploration_epsilon: 0.100, train_state_value: -0.245, normalized_return: 0.020, capped_normalized_return: 0.020, human_gap: 0.980
I0810 23:39:54.364759 130286664614976 run_atari.py:245] Training iteration 6.
I0810 23:39:55.178044 130286664614976 run_atari.py:252] Evaluation iteration 6.
I0810 23:40:12.065435 130286664614976 run_atari.py:280] iteration:   6, frame:  6000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  296, train_frame_rate: 1230, train_exploration_epsilon: 0.100, train_state_value: -0.303, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:40:12.369540 130286664614976 run_atari.py:245] Training iteration 7.
I0810 23:40:13.188268 130286664614976 run_atari.py:252] Evaluation iteration 7.
I0810 23:40:30.555599 130286664614976 run_atari.py:280] iteration:   7, frame:  7000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate: 1222, train_exploration_epsilon: 0.100, train_state_value: -0.296, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:40:30.839835 130286664614976 run_atari.py:245] Training iteration 8.
I0810 23:40:31.677985 130286664614976 run_atari.py:252] Evaluation iteration 8.
I0810 23:40:48.777481 130286664614976 run_atari.py:280] iteration:   8, frame:  8000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  292, train_frame_rate: 1193, train_exploration_epsilon: 0.100, train_state_value: -0.347, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:40:49.089202 130286664614976 run_atari.py:245] Training iteration 9.
I0810 23:40:49.925993 130286664614976 run_atari.py:252] Evaluation iteration 9.
I0810 23:41:06.488275 130286664614976 run_atari.py:280] iteration:   9, frame:  9000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  302, train_frame_rate: 1195, train_exploration_epsilon: 0.100, train_state_value: -0.304, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:41:06.801249 130286664614976 run_atari.py:245] Training iteration 10.
I0810 23:41:07.610854 130286664614976 run_atari.py:252] Evaluation iteration 10.
I0810 23:41:24.203904 130286664614976 run_atari.py:280] iteration:  10, frame: 10000, eval_episode_return: -21.00, train_episode_return: -3.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  301, train_frame_rate: 1235, train_exploration_epsilon: 0.100, train_state_value: -0.293, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:41:24.513666 130286664614976 run_atari.py:245] Training iteration 11.
I0810 23:41:25.351309 130286664614976 run_atari.py:252] Evaluation iteration 11.
I0810 23:41:42.087355 130286664614976 run_atari.py:280] iteration:  11, frame: 11000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  299, train_frame_rate: 1194, train_exploration_epsilon: 0.100, train_state_value: -0.284, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:41:42.381580 130286664614976 run_atari.py:245] Training iteration 12.
I0810 23:41:43.202148 130286664614976 run_atari.py:252] Evaluation iteration 12.
I0810 23:41:59.709585 130286664614976 run_atari.py:280] iteration:  12, frame: 12000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  303, train_frame_rate: 1219, train_exploration_epsilon: 0.100, train_state_value: -0.279, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:41:59.992350 130286664614976 run_atari.py:245] Training iteration 13.
I0810 23:42:00.835077 130286664614976 run_atari.py:252] Evaluation iteration 13.
I0810 23:42:17.375328 130286664614976 run_atari.py:280] iteration:  13, frame: 13000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  302, train_frame_rate: 1187, train_exploration_epsilon: 0.100, train_state_value: -0.307, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:42:17.657008 130286664614976 run_atari.py:245] Training iteration 14.
I0810 23:42:18.480790 130286664614976 run_atari.py:252] Evaluation iteration 14.
I0810 23:42:35.147882 130286664614976 run_atari.py:280] iteration:  14, frame: 14000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  300, train_frame_rate: 1214, train_exploration_epsilon: 0.100, train_state_value: -0.339, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:42:35.421021 130286664614976 run_atari.py:245] Training iteration 15.
I0810 23:42:36.242526 130286664614976 run_atari.py:252] Evaluation iteration 15.
I0810 23:42:53.015506 130286664614976 run_atari.py:280] iteration:  15, frame: 15000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  298, train_frame_rate: 1217, train_exploration_epsilon: 0.100, train_state_value: -0.325, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:42:53.323259 130286664614976 run_atari.py:245] Training iteration 16.
I0810 23:42:54.141812 130286664614976 run_atari.py:252] Evaluation iteration 16.
I0810 23:43:11.065448 130286664614976 run_atari.py:280] iteration:  16, frame: 16000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  295, train_frame_rate: 1222, train_exploration_epsilon: 0.100, train_state_value: -0.325, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:43:11.340142 130286664614976 run_atari.py:245] Training iteration 17.
I0810 23:43:12.161314 130286664614976 run_atari.py:252] Evaluation iteration 17.
I0810 23:43:28.968730 130286664614976 run_atari.py:280] iteration:  17, frame: 17000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  297, train_frame_rate: 1218, train_exploration_epsilon: 0.100, train_state_value: -0.365, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:43:29.250335 130286664614976 run_atari.py:245] Training iteration 18.
I0810 23:43:30.060720 130286664614976 run_atari.py:252] Evaluation iteration 18.
I0810 23:43:46.731327 130286664614976 run_atari.py:280] iteration:  18, frame: 18000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  300, train_frame_rate: 1234, train_exploration_epsilon: 0.100, train_state_value: -0.399, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:43:47.011891 130286664614976 run_atari.py:245] Training iteration 19.
I0810 23:43:47.838152 130286664614976 run_atari.py:252] Evaluation iteration 19.
I0810 23:44:05.109024 130286664614976 run_atari.py:280] iteration:  19, frame: 19000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  290, train_frame_rate: 1210, train_exploration_epsilon: 0.100, train_state_value: -0.317, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:44:05.415354 130286664614976 run_atari.py:245] Training iteration 20.
I0810 23:44:06.247217 130286664614976 run_atari.py:252] Evaluation iteration 20.
I0810 23:44:23.595671 130286664614976 run_atari.py:280] iteration:  20, frame: 20000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate: 1202, train_exploration_epsilon: 0.100, train_state_value: -0.309, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:44:23.879595 130286664614976 run_atari.py:245] Training iteration 21.
I0810 23:44:24.730507 130286664614976 run_atari.py:252] Evaluation iteration 21.
I0810 23:44:42.105191 130286664614976 run_atari.py:280] iteration:  21, frame: 21000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate: 1175, train_exploration_epsilon: 0.100, train_state_value: -0.308, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:44:42.388966 130286664614976 run_atari.py:245] Training iteration 22.
I0810 23:44:43.217463 130286664614976 run_atari.py:252] Evaluation iteration 22.
I0810 23:45:00.746081 130286664614976 run_atari.py:280] iteration:  22, frame: 22000, eval_episode_return: -21.00, train_episode_return: -2.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  285, train_frame_rate: 1207, train_exploration_epsilon: 0.100, train_state_value: -0.310, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:45:01.049882 130286664614976 run_atari.py:245] Training iteration 23.
I0810 23:45:01.889344 130286664614976 run_atari.py:252] Evaluation iteration 23.
I0810 23:45:19.252603 130286664614976 run_atari.py:280] iteration:  23, frame: 23000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate: 1191, train_exploration_epsilon: 0.100, train_state_value: -0.349, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:45:19.526395 130286664614976 run_atari.py:245] Training iteration 24.
I0810 23:45:20.361308 130286664614976 run_atari.py:252] Evaluation iteration 24.
I0810 23:45:37.281791 130286664614976 run_atari.py:280] iteration:  24, frame: 24000, eval_episode_return: -21.00, train_episode_return: -4.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  296, train_frame_rate: 1198, train_exploration_epsilon: 0.100, train_state_value: -0.322, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:45:37.585026 130286664614976 run_atari.py:245] Training iteration 25.
I0810 23:45:38.409937 130286664614976 run_atari.py:252] Evaluation iteration 25.
I0810 23:45:56.042903 130286664614976 run_atari.py:280] iteration:  25, frame: 25000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  284, train_frame_rate: 1212, train_exploration_epsilon: 0.100, train_state_value: -0.294, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:45:56.341982 130286664614976 run_atari.py:245] Training iteration 26.
I0810 23:45:57.190232 130286664614976 run_atari.py:252] Evaluation iteration 26.
I0810 23:46:14.842694 130286664614976 run_atari.py:280] iteration:  26, frame: 26000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  283, train_frame_rate: 1179, train_exploration_epsilon: 0.100, train_state_value: -0.303, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:46:15.115957 130286664614976 run_atari.py:245] Training iteration 27.
I0810 23:46:15.943522 130286664614976 run_atari.py:252] Evaluation iteration 27.
I0810 23:46:33.429353 130286664614976 run_atari.py:280] iteration:  27, frame: 27000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  286, train_frame_rate: 1209, train_exploration_epsilon: 0.100, train_state_value: -0.328, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:46:33.722816 130286664614976 run_atari.py:245] Training iteration 28.
I0810 23:46:34.543652 130286664614976 run_atari.py:252] Evaluation iteration 28.
I0810 23:46:51.106901 130286664614976 run_atari.py:280] iteration:  28, frame: 28000, eval_episode_return: -20.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  302, train_frame_rate: 1218, train_exploration_epsilon: 0.100, train_state_value: -0.317, normalized_return: 0.020, capped_normalized_return: 0.020, human_gap: 0.980
I0810 23:46:51.378350 130286664614976 run_atari.py:245] Training iteration 29.
I0810 23:46:52.214270 130286664614976 run_atari.py:252] Evaluation iteration 29.
I0810 23:47:09.116938 130286664614976 run_atari.py:280] iteration:  29, frame: 29000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  296, train_frame_rate: 1197, train_exploration_epsilon: 0.100, train_state_value: -0.311, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:47:09.390795 130286664614976 run_atari.py:245] Training iteration 30.
I0810 23:47:10.213485 130286664614976 run_atari.py:252] Evaluation iteration 30.
I0810 23:47:27.744786 130286664614976 run_atari.py:280] iteration:  30, frame: 30000, eval_episode_return: -21.00, train_episode_return: -2.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  285, train_frame_rate: 1216, train_exploration_epsilon: 0.100, train_state_value: -0.324, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:47:28.047508 130286664614976 run_atari.py:245] Training iteration 31.
I0810 23:47:28.887652 130286664614976 run_atari.py:252] Evaluation iteration 31.
I0810 23:47:46.492638 130286664614976 run_atari.py:280] iteration:  31, frame: 31000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  284, train_frame_rate: 1191, train_exploration_epsilon: 0.100, train_state_value: -0.300, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:47:46.766056 130286664614976 run_atari.py:245] Training iteration 32.
I0810 23:47:47.588529 130286664614976 run_atari.py:252] Evaluation iteration 32.
I0810 23:48:04.688134 130286664614976 run_atari.py:280] iteration:  32, frame: 32000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  292, train_frame_rate: 1216, train_exploration_epsilon: 0.100, train_state_value: -0.269, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:48:04.982027 130286664614976 run_atari.py:245] Training iteration 33.
I0810 23:48:05.810303 130286664614976 run_atari.py:252] Evaluation iteration 33.
I0810 23:48:23.091670 130286664614976 run_atari.py:280] iteration:  33, frame: 33000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate: 1208, train_exploration_epsilon: 0.100, train_state_value: -0.304, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:48:23.385279 130286664614976 run_atari.py:245] Training iteration 34.
I0810 23:48:24.215909 130286664614976 run_atari.py:252] Evaluation iteration 34.
I0810 23:48:41.399550 130286664614976 run_atari.py:280] iteration:  34, frame: 34000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  291, train_frame_rate: 1204, train_exploration_epsilon: 0.100, train_state_value: -0.310, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:48:41.695914 130286664614976 run_atari.py:245] Training iteration 35.
I0810 23:48:42.520385 130286664614976 run_atari.py:252] Evaluation iteration 35.
I0810 23:48:59.681495 130286664614976 run_atari.py:280] iteration:  35, frame: 35000, eval_episode_return: -20.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  291, train_frame_rate: 1213, train_exploration_epsilon: 0.100, train_state_value: -0.309, normalized_return: 0.020, capped_normalized_return: 0.020, human_gap: 0.980
I0810 23:48:59.968998 130286664614976 run_atari.py:245] Training iteration 36.
I0810 23:49:00.805560 130286664614976 run_atari.py:252] Evaluation iteration 36.
I0810 23:49:18.051897 130286664614976 run_atari.py:280] iteration:  36, frame: 36000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  290, train_frame_rate: 1196, train_exploration_epsilon: 0.100, train_state_value: -0.312, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:49:18.331664 130286664614976 run_atari.py:245] Training iteration 37.
I0810 23:49:19.171765 130286664614976 run_atari.py:252] Evaluation iteration 37.
I0810 23:49:36.437304 130286664614976 run_atari.py:280] iteration:  37, frame: 37000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  290, train_frame_rate: 1191, train_exploration_epsilon: 0.100, train_state_value: -0.345, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:49:36.740067 130286664614976 run_atari.py:245] Training iteration 38.
I0810 23:49:37.582978 130286664614976 run_atari.py:252] Evaluation iteration 38.
I0810 23:49:54.520052 130286664614976 run_atari.py:280] iteration:  38, frame: 38000, eval_episode_return: -21.00, train_episode_return: -5.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  295, train_frame_rate: 1187, train_exploration_epsilon: 0.100, train_state_value: -0.331, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:49:54.804626 130286664614976 run_atari.py:245] Training iteration 39.
I0810 23:49:55.634913 130286664614976 run_atari.py:252] Evaluation iteration 39.
I0810 23:50:12.966832 130286664614976 run_atari.py:280] iteration:  39, frame: 39000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  288, train_frame_rate: 1205, train_exploration_epsilon: 0.100, train_state_value: -0.344, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
I0810 23:50:13.264071 130286664614976 run_atari.py:245] Training iteration 40.
I0810 23:50:14.100147 130286664614976 run_atari.py:252] Evaluation iteration 40.
I0810 23:50:31.409453 130286664614976 run_atari.py:280] iteration:  40, frame: 40000, eval_episode_return: -21.00, train_episode_return: -6.00, eval_num_episodes:   1, train_num_episodes:   0, eval_frame_rate:  289, train_frame_rate: 1196, train_exploration_epsilon: 0.100, train_state_value: -0.376, normalized_return: -0.008, capped_normalized_return: -0.008, human_gap: 1.008
